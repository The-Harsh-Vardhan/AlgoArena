{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a41c457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\harsh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.16.2)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.2 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\harsh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (4.25.8)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\harsh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (69.0.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (4.13.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.26.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.2->tensorflow) (0.42.0)\n",
      "Requirement already satisfied: rich in c:\\users\\harsh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\harsh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\harsh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (0.12.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow) (2024.7.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\harsh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Traditional ML algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Gradient Boosting\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Dataset\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "# Utilities\n",
    "import json\n",
    "import os\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4136a88",
   "metadata": {},
   "source": [
    "# üñºÔ∏è Image Data Algorithms - Fashion-MNIST Classification\n",
    "\n",
    "Welcome to the Image Data arena! In this notebook, we'll apply various machine learning algorithms to the **Fashion-MNIST dataset** - a more challenging alternative to the classic MNIST digits dataset.\n",
    "\n",
    "## üìä Dataset: Fashion-MNIST\n",
    "\n",
    "- **Source**: Zalando's article images\n",
    "- **Classes**: 10 fashion categories (T-shirt, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot)\n",
    "- **Size**: 60,000 training + 10,000 test images\n",
    "- **Image Dimensions**: 28x28 grayscale pixels\n",
    "- **Goal**: Multi-class classification of fashion items\n",
    "\n",
    "---\n",
    "\n",
    "## üõ†Ô∏è Step 1: Load and Explore the Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97aeee7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Fashion-MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Fashion-MNIST class names\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Training labels shape: {y_train.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}\")\n",
    "print(f\"Test labels shape: {y_test.shape}\")\n",
    "print(f\"Number of classes: {len(class_names)}\")\n",
    "print(f\"Pixel value range: {X_train.min()} - {X_train.max()}\")\n",
    "\n",
    "# Visualize sample images\n",
    "plt.figure(figsize=(15, 8))\n",
    "for i in range(20):\n",
    "    plt.subplot(4, 5, i + 1)\n",
    "    plt.imshow(X_train[i], cmap='gray')\n",
    "    plt.title(f'{class_names[y_train[i]]}')\n",
    "    plt.axis('off')\n",
    "plt.suptitle('Fashion-MNIST Sample Images', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Class distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "plt.bar([class_names[i] for i in unique], counts)\n",
    "plt.title('Class Distribution in Training Set')\n",
    "plt.xlabel('Fashion Categories')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Class distribution:\")\n",
    "for i, count in enumerate(counts):\n",
    "    print(f\"{class_names[i]}: {count} samples ({count/len(y_train)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66732125",
   "metadata": {},
   "source": [
    "## üîß Step 2: Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5407316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9018 - loss: 0.2787\n"
     ]
    }
   ],
   "source": [
    "# Normalize pixel values to [0, 1]\n",
    "X_train_normalized = X_train.astype('float32') / 255.0\n",
    "X_test_normalized = X_test.astype('float32') / 255.0\n",
    "\n",
    "# For traditional ML algorithms, flatten the images\n",
    "X_train_flat = X_train_normalized.reshape(X_train_normalized.shape[0], -1)\n",
    "X_test_flat = X_test_normalized.reshape(X_test_normalized.shape[0], -1)\n",
    "\n",
    "print(f\"Flattened training data shape: {X_train_flat.shape}\")\n",
    "print(f\"Flattened test data shape: {X_test_flat.shape}\")\n",
    "\n",
    "# For memory efficiency, let's use a subset for traditional ML algorithms\n",
    "# (Fashion-MNIST is larger than traditional tabular datasets)\n",
    "subset_size = 10000\n",
    "X_train_subset = X_train_flat[:subset_size]\n",
    "y_train_subset = y_train[:subset_size]\n",
    "\n",
    "print(f\"Using subset of {subset_size} samples for traditional ML algorithms\")\n",
    "print(f\"Subset shape: {X_train_subset.shape}\")\n",
    "\n",
    "# For CNNs, prepare data with channel dimension\n",
    "X_train_cnn = X_train_normalized.reshape(-1, 28, 28, 1)\n",
    "X_test_cnn = X_test_normalized.reshape(-1, 28, 28, 1)\n",
    "\n",
    "print(f\"CNN input shape: {X_train_cnn.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac5b154",
   "metadata": {},
   "source": [
    "## ü§ñ Step 3: Traditional Machine Learning Algorithms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09d9783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize algorithms\n",
    "algorithms = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    'SVM (RBF)': SVC(kernel='rbf', random_state=42, probability=True),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5, n_jobs=-1),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'XGBoost': xgb.XGBClassifier(random_state=42, eval_metric='mlogloss'),\n",
    "    'LightGBM': lgb.LGBMClassifier(random_state=42, verbose=-1),\n",
    "    'CatBoost': CatBoostClassifier(random_state=42, verbose=False)\n",
    "}\n",
    "\n",
    "# Store results\n",
    "results = {}\n",
    "\n",
    "print(\"üöÄ Starting algorithm comparison...\")\n",
    "\n",
    "# Train and evaluate each algorithm\n",
    "for name, algorithm in algorithms.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    \n",
    "    # Measure training time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Train the model\n",
    "    algorithm.fit(X_train_subset, y_train_subset)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = algorithm.predict(X_test_flat)\n",
    "    \n",
    "    # Calculate training time\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Cross-validation score (on subset for speed)\n",
    "    cv_scores = cross_val_score(algorithm, X_train_subset, y_train_subset, cv=3, scoring='accuracy')\n",
    "    cv_mean = cv_scores.mean()\n",
    "    cv_std = cv_scores.std()\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'cv_mean': cv_mean,\n",
    "        'cv_std': cv_std,\n",
    "        'training_time': training_time,\n",
    "        'predictions': y_pred.tolist(),\n",
    "        'confusion_matrix': confusion_matrix(y_test, y_pred).tolist()\n",
    "    }\n",
    "    \n",
    "    print(f\"‚úÖ {name}: Accuracy = {accuracy:.4f}, CV Score = {cv_mean:.4f} (¬±{cv_std:.4f}), Time = {training_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3511ec",
   "metadata": {},
   "source": [
    "## üß† Step 4: Deep Learning Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e315a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Neural Network\n",
    "def create_simple_nn():\n",
    "    model = keras.Sequential([\n",
    "        layers.Flatten(input_shape=(28, 28)),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Convolutional Neural Network\n",
    "def create_cnn():\n",
    "    model = keras.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "print(\"üß† Deep Learning models defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91024dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Simple Neural Network\n",
    "print(\"Training Simple Neural Network...\")\n",
    "start_time = time.time()\n",
    "\n",
    "nn_model = create_simple_nn()\n",
    "nn_model.compile(optimizer='adam',\n",
    "                 loss='sparse_categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "# Train with validation split\n",
    "history_nn = nn_model.fit(X_train_normalized, y_train,\n",
    "                          epochs=10,\n",
    "                          batch_size=128,\n",
    "                          validation_split=0.1,\n",
    "                          verbose=1)\n",
    "\n",
    "# Evaluate\n",
    "nn_loss, nn_accuracy = nn_model.evaluate(X_test_normalized, y_test, verbose=0)\n",
    "nn_training_time = time.time() - start_time\n",
    "nn_predictions = np.argmax(nn_model.predict(X_test_normalized), axis=1)\n",
    "\n",
    "# Store results\n",
    "results['Simple Neural Network'] = {\n",
    "    'accuracy': nn_accuracy,\n",
    "    'loss': nn_loss,\n",
    "    'training_time': nn_training_time,\n",
    "    'predictions': nn_predictions.tolist(),\n",
    "    'confusion_matrix': confusion_matrix(y_test, nn_predictions).tolist(),\n",
    "    'history': history_nn.history\n",
    "}\n",
    "\n",
    "print(f\"‚úÖ Simple NN: Accuracy = {nn_accuracy:.4f}, Loss = {nn_loss:.4f}, Time = {nn_training_time:.2f}s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
